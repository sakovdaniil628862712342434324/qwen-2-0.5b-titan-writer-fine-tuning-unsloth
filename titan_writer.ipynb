{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Kncicf0oOVl"
      },
      "outputs": [],
      "source": [
        "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29 peft trl triton\n",
        "!pip install --no-deps cut_cross_entropy unsloth_zoo\n",
        "!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "!pip install --no-deps unsloth\n",
        "!pip install -U peft transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eSvM9zX_2d3"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"titan-writer\",\n",
        "    max_seq_length=2048,\n",
        "    dtype=None,\n",
        "    load_in_4bit=True\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 256,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\", \"embed_tokens\", \"lm_head\"],\n",
        "    lora_alpha = 256,\n",
        "    lora_dropout = 0.01,\n",
        "    bias = \"all\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 42,\n",
        "    use_rslora = True,\n",
        "    loftq_config = None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJqSzGO3sHzH"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/datasets/titan-writer.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95_Nn-89DhsL"
      },
      "outputs": [],
      "source": [
        "from unsloth import UnslothTrainer, UnslothTrainingArguments\n",
        "trainer = UnslothTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=2048,\n",
        "    packing=False,\n",
        "    args=UnslothTrainingArguments(\n",
        "        output_dir=\"titan-writer-checkpoint\",\n",
        "        per_device_train_batch_size=8,\n",
        "        gradient_accumulation_steps=1,\n",
        "        num_train_epochs = 10,\n",
        "        learning_rate=1e-4,\n",
        "        embedding_learning_rate=1e-5,\n",
        "        fp16=True,\n",
        "        logging_steps=1,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"constant\",\n",
        "        seed=42,\n",
        "        max_grad_norm=1.0,\n",
        "        report_to=\"tensorboard\",\n",
        "        save_strategy = \"epoch\",\n",
        "        save_steps=1,\n",
        "        gradient_checkpointing=True,\n",
        "    ),\n",
        ")\n",
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHDcED9uMYGe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"titan-writer\",\n",
        "    low_cpu_mem_usage=True,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map={\"\": 0},\n",
        ")\n",
        "model = PeftModel.from_pretrained(base_model, \"/content/titan-writer-checkpoint\")\n",
        "merged_model = model.merge_and_unload()\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/titan-writer-checkpoint\", trust_remote_code=True)\n",
        "tokenizer.padding_side = \"right\"\n",
        "merged_model.save_pretrained(\"titan-writer-model\")\n",
        "tokenizer.save_pretrained(\"titan-writer-model\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}